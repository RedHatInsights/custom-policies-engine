= Policies Engine documentation for Developers
:description: Policies Engine Developer Guide
:toc: macro
:toc-title:

toc::[]

== Introduction

Policies Engine provides ..

=== Alerting Philosophy

Alerting is useful, necessary, and typically an integral part of operational sanity.  Done well it strikes the perfect balance between human intervention and automation.  Done poorly it is an ineffective nuisance.  Hawkular Alerting tries to provide the tools to do things well, but it can just as easily be abused.  Alerts bring attention to a problem, or developing problem.  That problem typically requires human intervention to resolve.  As best as possible the alert should represent high level symptoms that affect a user experience.  The number of generated alerts should be small because a human can only respond to a few situations daily.  The same alert should likely not be repeated, or repeated only if a response has not been initiated.

==== Alerts

Alerts are generated when an Alert Trigger fires, based on a set of defined conditions that have been matched, possibly more than once or have held true over a period of time. When fired the trigger can perform actions, typically but not limited to notifications (e-mail, sms, etc). Alerts then start moving through the Open, Acknowledged, Resolved life-cycle.  There are many options on triggers to help ensure that alerts are not generated too frequently, including ways of automatically disabling and enabling the trigger.

==== Events

As discussed above the number of alerts should be small in order to be manageable.  But it can be useful to capture interesting happenings in the monitored world. This is called an Event in Hawkular Alerting.  An event can be roughly thought of as an alert without lifecycle.  Like alerts, an event can be generated by a trigger but unlike an alert, it can also be injected directly via the API, so it is very easy for clients to insert events as desired.  And although trigger-generated events can define actions to be performed, in general an event does not need human intervention.  Instead, it is typically something that can contribute to an alert firing, help investigate an alert, or simply help understand system behavior.

It is expected that the number of Events can be very large compared to the number of Alerts. Events (like Alerts), can be flexibly queried.


== Triggers

A Trigger defines the conditions that when satisfied will cause the trigger to fire an Alert.  Triggers can have one or more conditions and can optionally fire when ANY or ALL of the conditions are met. A trigger can generate an Alert or an Event.


=== Conditions

There are several different kinds of conditions but they all have one thing in common, each requires some piece of data against which the condition is evaluated.  Here are the different kinds of conditions:

* Availability
** X is DOWN
* Compare
** X < 80% Y
* Event
** event.id starts 'IDXYZ', event.tag.category == 'Server',
   event.tag.from ends '.com'
* Missing
** No event/data received for X in the last 5 minutes
* Nelson
** Detect Rule1,Rule2 scenarios for X
** https://en.wikipedia.org/wiki/Nelson_rules
* Rate
** X > 10 per-minute
* String
** X starts with "ABC", X matches "A.*B"
* Threshold
** X < 10, X >= 20
* ThresholdRange
** X inside [10,20), X outside [100,200]

Most conditions deal with numeric data.  But String and Availability data is also supported.  A trigger can combine conditions dealing with data of different types and from different sources.

=== Event condition language

The event query language is written in the form of statements, where each ``statement`` is a ``predicate`` or another ``statement``. A ``statement`` can be expressed as ``statement logical_operator statement``, where the available ``logical_operators`` are ``AND`` and ``OR``. Each ``statement`` can be included inside parenthesis ``(``, ``)``. Insignificant whitespace is not evaluated. ``Statement`` can also be a negative form of ``statement`` with ``NOT`` operator.

A predicate is written in the form of ``key operator value``. ``Key`` is a field name inside the event data while ``value`` is static input given in the ``predicate``. Allowed ``operators`` differ depending on the data type of ``key`` or ``value``. Available ``operators`` are listed below.

Numeric operators only accept numbers as ``key`` and ``value`` type, while string operators can be used with any number or string type. Array operators require array as ``key`` or ``value`` type and the allowed combinations are listed below.

Number type is equivalent to integer or floating point value. Floating point value can be expressed with dot ``.`` only, not with comma (as is used in certain locales). A string can be quoted with ``'``, ``"``. Values without quotes are parsed as string at this point, but it is recommended to quote all the string values to separate them from ``keys``.

All the operators are case-insignificant. The language definition can be found from link:https://github.com/RedHatInsights/policies-engine/blob/cb60fc58adf2dab2bc9366041ad758718d1b8936/api/src/main/antlr4/com/redhat/cloud/custompolicies/api/model/condition/expression/parser/Expression.g4[here].

.Field operators
|===
|Predicate |Description

|
|Key exists in the input data, no value or operator is given.
|===

.Numeric operators
|===
|Predicate |Description

|=
|Equal

|!=
|Not equal

|>
|Larger than

|>=
|Larger than or equal

|<
|Smaller than

|\<=
|Smaller than or equal

|===

.String operators
|===
|Predicate |Description

|=
|Equal

|!=
|Not equal

|CONTAINS
|Expression substring matches any part of the input
|===

Array operators can have different key input type and value types, but everything is threated as a string in both input as well as in the predicate.

.Array operators
|===
|Predicate |Description |Value type |Key type

|IN
|Any array value is in the key's value
|Array
|String

|CONTAINS
|All values are in the key's value
|String
|String or Array
|===

==== Examples

All the examples are considering the following input:

[source,json]
----
{
  "a": "b",
  "b": 3,
  "c": [
    "d",
    "e",
    "home"
  ],
  "f": 2.0,
  "g": "time",
}
----

===== String examples

String queries will always work, even if the input has numeric values. In that case, the values are converted to strings before comparison.
For example, ``a = 'b' AND b = '3'`` is true since ``b`` is considered a string in this case.

With operators that can have array or string inputs, the type is meaningful. ``g contains 'tim'`` is a string comparison, while ``c contains 'home'`` would not match, since it is exact match inside the array.

If multiple possible values are wanted for exatch match, then the ``IN`` operator is useful. For example, ``a IN ['b', 'c']`` would be valid since ``b`` is equal to ``a``'s value.

===== Numeric examples

Compare operators such as ``b > 3`` can be used with floating points also, such as ``f >= 2``.

Range query could be expresssed as ``b > 3 AND b \<= 4``.

===== Complex statements and negations

As each statement can be expressed with parenthesis, the expression might be easier to read or more complex combination of logical operators can be created.

``\((a != 'b') OR (b AND NOT (c CONTAINS 'tim' AND g = 'time'))`` can be split to parts and each evaluated with this resulting in true:

* ``(a != 'b')`` is false

* ``b`` is true

* ``(c CONTAINS 'tim' AND g = 'time')`` is false, but ``NOT`` turns it to true

* The end result is: ``false OR (true AND true)`` which is then true.

The special form of ``(b)`` means that ``b`` key must exists in the input data, but the value is not significant. The ``NOT`` operator negates the result of ``(c CONTAINS 'tim' AND g = 'time'``

=== Actions

The whole purpose of alerting is to be able to immediately respond to a developing or active problem. Policies Engine provides several plugins to take action when alerts are generated. Custom action plugins can be defined as well. The available plugins do not have any features in this repository other than setting and defining properties, but instead they always write to external queue (such as Kafka) from which the next process continues.

The following notification types are currently supported out of the box:

* E-mail notifications
* Webhook notifications

=== Trigger Dampening

It's often the case that one doesn't want a trigger to fire every time a condition set is met.  Instead, one wants to ensure that the issue is not a spike of activity, or that one doesn't flood an on-call engineer with alerts.  Hawkular Alerting provides several way of ensuring triggers fire only as desired. We call this "_Trigger Dampening_".  An example is useful for understanding dampening.

Let's say we have a trigger with a single condition: responseTime > 1s.

It is important to understand how the reporting interval plays into alerting, and into dampening.  Assume responseTime is reported every 15s.  That means we get roughly 4 data points every minute, and therefore evaluate the condition around 4 times a minute.

Here are the different trigger dampening types:

==== Strict
* N consecutive true evaluations
* Useful for ignoring spikes in activity or waiting for a prolonged event

In our example this could be, "Fire the trigger only if responseTime > 1s for 6 consecutive evaluations".  So, given a 15s reporting interval this means response time would likely have been high for about 90s.  But note that if the reporting interval changes the firing time will change.  This is used more when the number of evaluations is more important than the time it takes to fire.

Note that default dampening for triggers is Strict(1).  Which just means that by default a trigger fires every time it's condition set evaluates to true.

==== Relaxed Count
* N true evaluations out of M total evaluations
* Useful for ignoring short spikes in activity but catching frequently spiking activity

In our example this could be, "Fire the trigger only if responseTime > 1s for 4 of 8 evaluations".  This means the trigger will fire if roughly half the time we are exceeding a 1s response time.  Given a 15s reporting interval this means the trigger could fire in 1 to 2 minutes of accumulated evaluations. But note that if the reporting interval changes the firing time will change.  This is used more when the number of evaluations is more important than the time it takes to fire.

==== Relaxed Time
* N true evaluations in T time
* Useful for ignoring short spikes in activity but catching frequently spiking activity

In our example this could be, "Fire the trigger only if responseTime > 1s 4 times in 5 minutes".  This means the trigger will fire if we exceed 1s response time multiple times in a 5 minute period. Given a 15s reporting interval this means the trigger could fire in 1 to 5 minutes of accumulated evaluations. But note that if the reporting interval changes the firing time will change. And also note that the trigger will never fire if we don't receive at least 4 reports in the specified 5 minute period. This is used when you don't want to exceed a certain period of time before firing.

==== Strict Time
* Only true evaluations for at least T time
* Useful for reporting a continued aberration

In our example this could be, "Fire the trigger only if responseTime > 1s for at least 5 minutes".  This means the trigger will fire if we exceed 1s response time on every report for a 5 minute period. Given a 15s reporting interval this means the trigger will fire after roughly 20 consecutive true evaluations. Note that if the reporting interval changes the firing time will remain roughly the same.  It is important to understand that at least 2 evaluations are required.  The first true evaluation starts the clock. Any false evaluation stops the clock. Assuming only true evaluations, the trigger fires on the first true evaluation at or after the specified period.  The shorter the reporting interval the closer the firing time will be to the specified period, T.

==== Strict Timeout
* Only true evaluations for T time
* Useful for reporting a continued aberration with a more guaranteed firing time

In our example this could be, "Fire the trigger only if responseTime > 1s for 5 minutes".  This means the trigger will fire if we exceed 1s response time on every report for a 5 minute period. Given a 15s reporting interval this means the trigger will fire after roughly 20 consecutive true evaluations. Note that if the reporting interval changes the firing time will remain the same.  It is important to understand that only 1 evaluation is required.  The first true evaluation starts the clock. Assuming only true evaluations, the trigger fires at T, when a timer expires and fires the trigger. Any false evaluation stops the clock and cancels the timer. This type of dampening has more processing overhead because the trigger evaluation requires an external timer.

=== AutoDisable

A trigger can be set for AutoDisable.  Whereas dampening can limit the firing rate of a trigger, disabling a trigger completely stops the trigger from firing (or being evaluated).  A trigger can be manually enabled and disabled, via the REST API, but it can also be disabled automatically. If the trigger has the autoDisable option set to true then after it fires it id disabled, preventing any subsequent alerts until manually re-enabled.  The default is false.

=== AutoEnable

A trigger can be set for AutoEnable.  If AutoEnable is true then when an alert is resolved, and if all alerts for the trigger are then resolved, the trigger will be enabled if it is currently disabled.  This ensures that the trigger will again go into firing mode, without needing to be manually enabled by the user. The default is false.

=== Source

By default both Triggers and Data ignore "source".  This means that the dataIds defined on a trigger's conditions are matched against the dataIds on incoming data (within a tenant) and matching data is evaluated against the conditions.  It is possible to qualify triggers and data with a "source" such that a trigger only evaluates data having the same source.

This mechanism is used automatically by <<Data-Driven Group Triggers>> but can be used manually as well.  If you find that data is better described using a combination source+id, as opposed to just id, then this approach may be appropriate.


== Group Triggers

It's often the case that the same alerting needs to be applied to all instances of the same thing.  For example, it may be useful to alert on "System Load > 80%" on 50 different CPUs.  It can be cumbersome to manage 50 individual triggers.

A Group Trigger allows you to define a single trigger and then apply it to a group of logically similar things.  A group trigger could be used in the example above.  Then, a member could be added for each CPU.  The member triggers are basically managed copies of the group trigger.  Changes at the group level are pushed down to the members. So, to change "80%" to "85%", or to change autoDisable from false to true, only the group trigger must be changed.

=== Managing DataIds

The group trigger is basically a template, it is not deployed.  Only the member triggers are deployed and actively evaluated because only the member triggers are associated with real dataIds on the conditions.  The group trigger uses "tokens" for the dataIds and each member, when defined, must provide a map of dataId token replacements.

Using the example above, our group trigger would define a condition using a dataId token, like:

[source,java]
----
{ type: "threshold",
  dataId: "SystemLoad",
  operator: "GT"
  threshold: "80.0"
}
----

When adding a member for a specific CPU, say CPU-1, we'd map the token to the real dataId, something like:

[source,java]
----
dataIdMap: {
  "SystemLoad":"CPU-1_SystemLoad"
}
----

Where "CPU-1_SystemLoad" reflects the actual id associated with system load data sent to alerts for CPU-1.

When updating conditions at the group level it is necessary to supply dataId mappings for all of the existing members because the dataIds may have changed on the new condition set.


=== Orphans

There are times when a particular group member may need to managed individually.  For example, if a single CPU is of particular concern it may be useful to change the threshold level on just that member.  It is possible to orphan a member trigger and manage it independently, while maintaining it's association with the group trigger.  It can be unorphaned at any time, and reset to the group settings.


=== Data-Driven Group Triggers

[since 0.9.0.Final]

Group triggers allow a common definition to be applied to logically similar members. For example, a group trigger could be defined for alerting on CPU SystemLoad and a member trigger would be added for every CPU, each a copy of the group trigger but working against the proper dataId(s) given the CPU instance. When a member is added a map from the group's [token] dataIds to the members [real] dataIds must be provided. And if updating conditions at the group level a map for each existing member must be provided. This makes sense, and is fine, but it can be tedious, or difficult to supply.

It's not uncommon for the member-level dataIds to be a concatenation of id of the source member (e.g. a resourceId, CPU-1, etc) and the group level dataId token (SystemLoad). So you end up with member-level ids like 'CPU-1_SystemLoad' where the "source" is 'CPU-1' and the dataId is 'SystemLoad'.

Data-Driven Group Triggers are able to add member triggers to a group automatically, one for each "source" of the same data. In other words, for a group trigger on CPU SystemLoad, add a member automatically for each source CPU reporting the 'SystemLoad' metric. By reporting data as a combination of source and dataId this should be possible. So, instead of reporting:

[source,java]
----
Data(id:cpu-1-Load, value:123)
----

We'd want:

[source,java]
----
Data(source:cpu-1, id:Load, value:123)
----

This would then relieve the client from having to add member triggers up front and instead assume that the group will grow as needed, based on the incoming data.

Because dataIds are often defined upstream it is not always possible to supply Hawkular Alerting with data such that the source and id are separated.  But if possible this is a power ful approach.


==== Behavioral Notes

A couple of notes about data-driven group triggers:

* Each member trigger is associated with a single source and only considers data from that source.
** True for single and mult-condition triggers.
* Condition changes in the group trigger will remove all member triggers.
** The members will then again be created as the data demands.
* The <<Source>> mechanism can also be used with manually managed triggers, if desired.


== Alert Lifecycle

Hawkular Alerting can integrate with other systems to handle Alert Lifecycle, but alerts can also be managed directly within the tool.  Hawkular Alerting supports a typical move through a simple lifecycle.  An alert starts in OPEN status, optionally moves to ACKNOWLEDGED to indicate the alert has been seen and the issue is being resolved, and is finally set to RESOLVED to indicate the problem has been fixed.

=== AutoResolve

Triggers require firing conditions and always start in _Firing_ mode.  But the trigger can optionally supply autoResolve conditions. If _autoResolve=true_ then after a trigger fires it switches to _AutoResolve_ mode.  In AutoResolve mode the trigger no longer looks for problem conditions, but instead looks for evidence that the problem is resolved.  A simple example would be a trigger that has a firing condition of Availability DOWN, and an autoResolve condition of Availability UP.  This mechanism ensures that only one alert is generated for a problem, and that when the problem has been resolved, the trigger automatically returns to firing mode.

Moreover, if _autoResolveAlerts=true_ then when the AutoResolve conditions are satisfied all of its unresolved alerts will be automatically set RESOLVED.

Like Firing mode, AutoResolveMode can optionally define its own dampening setting.


== Tags

Tags can have a variety of uses but are commonly used to assist in search.  Tags are free-formed name-value pairs and can be applied to:

* Triggers
* Alerts
* Events

Tags on triggers are automatically passed on to the Alerts or Events generated by that trigger.  This allows the same search criteria used to fetch triggers to also be used to fetch the alerts or events generated by those triggers.

A tag's name and value must both be non-null.

=== Tags Query Language

[source]
----
<tag_query> ::= ( <expression> | "(" <object> ")"
| <object> <logical_operator> <object> )
<expression> ::= ( <tag_name> | <not> <tag_name>
| <tag_name> <boolean_operator> <tag_value>
| <tag_name> <array_operator> <array> )
<not> ::= [ "NOT" | "not" ]
<logical_operator> ::= [ "AND" | "OR" | "and" | "or" ]
<boolean_operator> ::= [ "=" | "!=" ]
<array_operator> ::= [ "IN" | "NOT IN" | "in" | "not in" ]
<array> ::= ( "[" "]" | "[" ( "," <tag_value> )* )
<tag_name> ::= <identifier>
<tag_value> ::= ( "'" <regexp> "'" | <simple_value> )
;
; <identifier> and <simple_value> follow pattern [a-zA-Z_0-9][\\-a-zA-Z_0-9]*
; <regexp> follows any valid Java Regular Expression format
----

== External Alert Integration

There are times when an external system will already be looking for and detecting potential issues in its environment.  It is possible for these detection-only systems to leverage the power of Hawkular Alerting' trigger and action infrastructure.  For example, let's say there is already a sensor in place looking for overheating situations.  When it detects something overheating it can take some action.  In this case we are not sending a stream of heat readings to alerting and having it evaluate against a threshold set on a trigger condition.  Instead, the threshold and evaluation are all built into the sensor.  To integrate with Hawkular Alerting we can use an "External Condition".

=== External Conditions

External integration begins with standard triggers.  In this way we immediately get everything that triggers offer: actions, dampening, lifecycle, auto-resolve, etc.  The difference is that instead of the typical condition types: Threshold, Availability, etc.., we can use an ExternalCondition. An external condition is like other conditions in that it has a 'dataId' with which it matches data sent into Hawkular Alerting.  It also has 'systemId' and 'expression' fields. The systemId is used to identify the external system for which the condition is relevant. In our example, perhaps "HeatSensors".  The expression field is used as needed.  In our example it may not be needed or it could be a description like, "sensor detected high temperature".  In other examples it could be used to store a complex expression that will be evaluated by the external system. 

The main thing about external conditions is that they always evaluate to true.  It is assumed that when a datum comes in with a dataId assigned to an external condition that that condition immediately evaluates to true.  A trigger with a single external condition (and default dampening) would fire on every datum sent in for it's condition.  This is because it is assumed the external system already did the work of determining there was an issue.  

Note that the string data sent in has any value the external alerter system wants it to be.  In our example it may  be a sensorId and temperature, like "Sensor 5368, temperature 212F".

== Action Plugins

Plugins are responsible to execute actions when an alert, or possibly an event, happens.

Actions can be a notification task or a complex process.

Policies Engine provides a plugin architecture to extend and add new behaviours.

=== Create a new plugin

The lifecycle of the a plugin is managed by Quarkus and the component must be annotated with ``@Plugin(name = "")``. This indicates that the plugin must be loaded and made available to the engine.

The plugin itself must implement `org.hawkular.alerts.actions.api.ActionPluginListener` interface.

For example:

[source,java]
----
@Plugin(name = "file")
public class FilePlugin implements ActionPluginListener {
    ...
}
----

=== ActionPluginListener interface

This interface has the responsibility of

* Define which properties and default values are supported by a plugin. A reserved property is called ``_managed`` which indicates the action does not necessarily take any properties and can be automatically created from the FullTrigger (with generated id only).

[source,java]
----
...
    /**
     * The alerts engine registers the plugins available with their properties.
     * This method is invoked at plugin registration time.
     *
     * @return a list of properties available on this plugin
     */
    Set<String> getProperties();

    /**
     * The alerts engine registers the plugins available with their default values.
     * This method is invoked at plugin registration time.
     * Default values can be modified by the alerts engine.
     *
     *
     * @return a list of default values for properties available on this plugin
     */
    Map<String, String> getDefaultProperties();
...
----

* Process an incoming action message wrapped as a `org.hawkular.alerts.actions.api.ActionMessage`

[source,java]
----
...
    /**
     * This method is invoked by the ActionService to process a new action generated by the engine.
     *
     * @param msg message received to be processed by the plugin
     * @throws Exception any problem
     */
    void process(ActionMessage msg) throws Exception;

    /**
     * Potentially flush the messages after a firing cycle has ended
     */
    void flush();
...
----

The ``flush()`` method is called after a processing cycle of DroolsEngine has completed. This allows to batch the output action messages and then send them in the flush if necessary.

=== ActionMessage interface

This interface is a wrapper of the action sent by the engine with the effective properties to use by the plugin to
process it.

[source,java]
----
package org.hawkular.alerts.actions.api;

import java.util.Map;

import org.hawkular.alerts.api.model.action.Action;

import com.fasterxml.jackson.annotation.JsonInclude;

/**
 * A message sent to the plugin from the alerts engine
 * It has the event payload as well as action properties
 *
 * @author Lucas Ponce
 */
public interface ActionMessage {

    @JsonInclude
    Action getAction();
}
----

The class `org.hawkular.alerts.api.model.action.Action` is generated for the engine and it has the event detail as
part of its payload.

[source,java]
----
/**
 * A base class for action representation from the perspective of the alerts engine.
 * An action is the abstract concept of a consequence of an event.
 * A Trigger definition can be linked with a list of actions.
 *
 * Alert engine only needs to know an action id and message/payload.
 * Action payload can optionally have an event as payload.
 *
 * Action plugins will be responsible to process the action according its own plugin configuration.
 *
 * @author Jay Shaughnessy
 * @author Lucas Ponce
 */
public class Action {

    @JsonInclude
    private String tenantId;

    @JsonInclude
    private String actionPlugin;

    @JsonInclude
    private String actionId;

    @JsonInclude(Include.NON_NULL)
    private String eventId;
...
}
----

=== Email Action Plugin

[cols="^2,10"]
|=====
| Plugin Name | *email*
|=====

[cols="^2,8,^2", options="header"]
|=======================
| Property |
Description |
Default value
| *_managed* | This is managed plugin | true |
|=======================

Email plugin takes no properties when created from the FullTrigger. It outputs a specific data model which is used by the link:https://github.com/RedHatInsights/policies-notifications[Policies Notifications] project to enrich the data with receivers, generate the email message and send it. More details in the project.

=== WebHook Action Plugin

[cols="^2,10"]
|=====
| Plugin Name | *webhook*
|=====

[cols="^2,8,^2", options="header"]
|=======================
| Property |
Description |
Default value
| *_managed* | This is managed plugin | true
| *endpoint_id* |
Endpoint id as defined in the link:https://github.com/RedHatInsights/policies-notifications[Policies Notifications] project
| -
|=======================

More details in the project how the message the is handled. Outputs all Action details in the output message with a defined ``endpoint_id``.

== Engine Extensions

WARNING: This feature has been disabled in the current codebase, but documentation remains since we might need it.

Engine extensions are listeners that can operate on Data or Events received before the engine process them.

Extensions can implement a variety of use cases where transformation or filtering of incoming Data or Events might be necessary.

Extensions are executed in a pipeline ordered by registration time.

Extensions must implement a DataExtension or EventExtension interface and be registered through the `ExtensionsService`.

=== DataExtension interface

[source,java]
----
public interface DataExtension {

    /**
     * The extension processes the supplied Data and returns Data to be forwarded, if any.
     *
     * @param data The Data to be processed by the extension.
     * @return The set of Data to be forwarded to the next extension, or core engine if this is the final extension.
     */
    TreeSet<Data> processData(TreeSet<Data> data);

}
----

=== EventExtension interface

[source,java]
----
public interface EventExtension {

    /**
     * The extension processes the supplied Events and returns Events to be forwarded, if any.
     *
     * @param events The Events to be processed by the extension.
     * @return The set of Events to be forwarded to the next extension, or core engine if this is the final extension.
     */
    TreeSet<Event> processEvents(TreeSet<Event> events);

}
----

== Events Aggregation Extension

The Events Aggregation Extension allows to scope Sliding Windows on _Events_ and define expressions on aggregated data.

To use this feature a _Trigger_ must have the _HawkularExtension_ tag with value _EventsAggregation_. It must then
define an _ExternalCondition_ with the _alerterId_ set to _EventsAggregation_, as shown in the example:

[source,json]
----
{
  "triggers":[
    {
      "trigger":{
        "id": "marketing-scenario",
        "name": "Marketing Scenario",
        "description": "Detect when a customer buys several items in a short period of time",
        "severity": "HIGH",
        "enabled": true,
        "actions":[
          {
            "actionPlugin": "email",
            "actionId": "notify-to-marketing"
          }
        ],
        "tags":{
            "HawkularExtension":"EventsAggregation"
        }
      },
      "conditions":[
        {
          "triggerMode": "FIRING",
          "type": "EXTERNAL",
          "alerterId":"EventsAggregation",
          "dataId": "marketing",
          "expression": "event:groupBy(context.accountId):window(time,10s):having(count > 2)"
        }
      ]
    }
  ],
  "actions":[
    {
      "actionPlugin": "email",
      "actionId": "notify-to-marketing",
      "properties": {
        "to": "marketing@hawkular.org"
      }
    }
  ]
}
----

All events tagged with _HawkularExtension_=_EventsAggregation_ will be filtered out and processed asynchronously by
the extension applying aggregated rules defined in the ExternalCondition expressions.

=== Events Aggregation Expressions

An _ExternalCondition_ used for _EventsAggregation_ alerter defines a DSL expression which is parsed internally by the
extension into a DRL format understandable by the JBoss Rules CEP engine.

The DSL expression defines Event grouping by fields and additional filtering options:

[source]
----
<expression> ::= "event:groupBy(" <field> ")" [ ":window(" <window> ")" ] [ ":filter(" <filter> ] [ ":having(" <having> ")" ]

<field> ::= [ "tag." | "context." ] <field name>

<window> ::= ( "time," <time_value> | "length," <numeric_value> )

<time_value> ::= [ <numeric_value> "d" ][ <numeric_value> "h" ][ <numeric_value> "m" ][ <numeric_value> "s" ] [ <numeric_value> [ "ms" ]]

<filter> ::= <drools_expression>

<having> ::= <drools_expression>
----

For example, the expression

[source]
event:groupBy(context.accountId):window(time,10s):having(count > 2)

can be described as follows

[source]
groupBy(context.accountId)      Group window events by context "accountId" field
window(time,10s)                Define a sliding time window of 10 seconds
having(count > 2)               Define an expression on the grouped events

In other words, this condition will be true, each time that there are more than two events with the same _accountId_ in a 10 seconds window.

The DSL can operate on Events fields, as well as context and tags, as it is shown in the previous example and here:

[source]
event:groupBy(tags.accountId):window(time,10s):having(count > 1, count.tags.location > 1)

where

[source]
groupBy(context.accountId)                    Group window events by context "accountId" field
window(time,10s)                              Define a sliding time window of 10 seconds
having(count > 1, count.tags.location > 1)    Define an expression on the grouped events

This condition will be true when there are more than 1 events with more than one _location_ tag, so detecting when
events for the same _accountId_ happens from different places.

The two previous expressions group all events for the timing window.

We might have scenarios where only specific events should be grouped.

For these cases we can add filters into the expressions like in the following example:

[source]
event:groupBy(tags.traceId):filter((category == "Credit Check" && text == "Exceptionally Good") || (category == "Stock Check" && text == "Out of Stock")):having(count > 1, count.tags.accountId == 1)

This expression will group events filtered by an expression

[source]
filter(
    (category == "Credit Check" && text == "Exceptionally Good") ||
    (category == "Stock Check" && text == "Out of Stock")
)

Note that this expression doesn't define an explicit sliding time window, so it will use a default expiration window.

Additional details can be consulted on the JavaDoc of the implementation and examples:

* link:https://github.com/hawkular/hawkular-alerts/blob/master/hawkular-alerts-engine-extensions/hawkular-alerts-events-aggregation/src/main/java/org/hawkular/alerts/extensions/Expression.java[Events Aggregation Expression JavaDoc]
* link:https://github.com/hawkular/hawkular-alerts/tree/master/examples/events-aggregation[Events Aggregation Expression Examples]

== REST API

Hawkular Alerting supports a robust REST API for managing Triggers, Alerts and Events.

* link:http://www.hawkular.org/docs/rest/rest-alerts-v2.html[Hawkular Alerting REST API]

